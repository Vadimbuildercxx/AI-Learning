{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "119c9460",
   "metadata": {},
   "source": [
    "## Home assignment 05: Bagging and OOB score\n",
    "\n",
    "Please, fill the lines in the code below.\n",
    "This is a simplified version of `BaggingRegressor` from `sklearn`. Please, notice, that `sklearn` API is **not preserved**.\n",
    "\n",
    "Your algorithm should be able to train different instances of the same model class on bootstrapped datasets and to provide [OOB score](https://en.wikipedia.org/wiki/Out-of-bag_error) for the training set.\n",
    "\n",
    "The model should be passed as model class with no explicit parameters and no parentheses.\n",
    "\n",
    "Example:\n",
    "```\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "bagging_regressor = SimplifiedBaggingRegressor(num_bags=10, oob=True)\n",
    "bagging_regressor.fit(LinearRegression, X, y)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ecde34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06110580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimplifiedBaggingRegressor:\n",
    "#     def __init__(self, num_bags, oob=False):\n",
    "#         self.num_bags = num_bags\n",
    "#         self.oob = oob\n",
    "        \n",
    "#     def _generate_splits(self, data: np.ndarray):\n",
    "#         '''\n",
    "#         Generate indices for every bag and store in self.indices_list list\n",
    "#         '''\n",
    "#         self.indices_list = []\n",
    "#         data_length = len(data)\n",
    "#         for bag in range(self.num_bags):\n",
    "#             self.indices_list.append(np.random.choice(data_length, data_length))\n",
    "        \n",
    "#     def fit(self, model_constructor, data, target):\n",
    "#         '''\n",
    "#         Fit model on every bag.\n",
    "#         Model constructor with no parameters (and with no ()) is passed to this function.\n",
    "        \n",
    "#         example:\n",
    "        \n",
    "#         bagging_regressor = SimplifiedBaggingRegressor(num_bags=10, oob=True)\n",
    "#         bagging_regressor.fit(LinearRegression, X, y)\n",
    "#         '''\n",
    "#         self.data = None\n",
    "#         self.target = None\n",
    "#         self._generate_splits(data)\n",
    "#         assert len(set(list(map(len, self.indices_list)))) == 1, 'All bags should be of the same length!'\n",
    "#         assert list(map(len, self.indices_list))[0] == len(data), 'All bags should contain `len(data)` number of elements!'\n",
    "#         self.models_list = []\n",
    "#         for bag in range(self.num_bags):\n",
    "#             model = model_constructor()\n",
    "#             data_bag, target_bag = data[self.indices_list[bag]], target[self.indices_list[bag]] # Your Code Here\n",
    "#             self.models_list.append(model.fit(data_bag, target_bag)) # store fitted models here\n",
    "#         if self.oob:\n",
    "#             self.data = data\n",
    "#             self.target = target\n",
    "        \n",
    "#     def predict(self, data):\n",
    "#         '''\n",
    "#         Get average prediction for every object from passed dataset\n",
    "#         '''\n",
    "#         preds = []\n",
    "#         for model in self.models_list:\n",
    "#             preds.append(model.predict(data))\n",
    "\n",
    "#         return np.mean(preds, axis=0)\n",
    "    \n",
    "#     def _get_oob_predictions_from_every_model(self):\n",
    "#         '''\n",
    "#         Generates list of lists, where list i contains predictions for self.data[i] object\n",
    "#         from all models, which have not seen this object during training phase\n",
    "#         '''\n",
    "#         # list_of_predictions_lists = [[] for _ in range(len(self.data))]\n",
    "\n",
    "#         # for (bag, model) in zip(self.indices_list, self.models_list):\n",
    "#         #     oob_indexes = np.setdiff1d(range(len(self.data)), bag)\n",
    "#         #     pred = model.predict(self.data[oob_indexes])\n",
    "#         #     list_of_predictions_lists.append(pred)\n",
    "#         #     list_of_predictions_indexes.append(oob_indexes)\n",
    "#         #     print(pred[:10])\n",
    "#         #     print(oob_indexes[:10])\n",
    "\n",
    "#         # self.list_of_predictions_indexes = np.array(list_of_predictions_indexes, dtype=object)\n",
    "#         # self.list_of_predictions_lists = np.array(list_of_predictions_lists, dtype=object)\n",
    "#         pass\n",
    "    \n",
    "#     def _get_averaged_oob_predictions(self):\n",
    "#         '''\n",
    "#         Compute average prediction for every object from training set.\n",
    "#         If object has been used in all bags on training phase, return None instead of prediction\n",
    "#         '''\n",
    "        \n",
    "#         preds = np.zeros(len(self.data))\n",
    "#         preds_count = np.zeros(len(self.data))\n",
    "\n",
    "#         for (bag, model) in zip(self.indices_list, self.models_list):\n",
    "#             oob_indexes = np.setdiff1d(range(len(self.data)), bag)\n",
    "#             pred = model.predict(self.data[oob_indexes])\n",
    "#             preds[oob_indexes] += pred\n",
    "#             preds_count[oob_indexes] += 1\n",
    "\n",
    "#         self.oob_predictions = np.divide(preds, preds_count) # Your Code Here\n",
    "        \n",
    "        \n",
    "#     def OOB_score(self):\n",
    "#         '''\n",
    "#         Compute mean square error for all objects, which have at least one prediction\n",
    "#         '''\n",
    "#         self._get_averaged_oob_predictions()\n",
    "#         return np.power(self.oob_predictions - self.target, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa174f",
   "metadata": {},
   "source": [
    "### Local tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaa2e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from tqdm.auto import tqdm\n",
    "from bagging import SimplifiedBaggingRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54221c2",
   "metadata": {},
   "source": [
    "#### Simple tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c94a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6267fb8ff74b400290381464ab736981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Vadim\\source\\AI-Learning\\YandexML\\task_5\\assignment_bagging_and_oob.ipynb Ячейка 7\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vadim/source/AI-Learning/YandexML/task_5/assignment_bagging_and_oob.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(X, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vadim/source/AI-Learning/YandexML/task_5/assignment_bagging_and_oob.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m bagging_regressor \u001b[39m=\u001b[39m SimplifiedBaggingRegressor(num_bags\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, oob\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Vadim/source/AI-Learning/YandexML/task_5/assignment_bagging_and_oob.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m bagging_regressor\u001b[39m.\u001b[39;49mfit(LinearRegression, X, y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vadim/source/AI-Learning/YandexML/task_5/assignment_bagging_and_oob.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m predictions \u001b[39m=\u001b[39m bagging_regressor\u001b[39m.\u001b[39mpredict(X)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vadim/source/AI-Learning/YandexML/task_5/assignment_bagging_and_oob.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39mmean((predictions \u001b[39m-\u001b[39m y)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m<\u001b[39m \u001b[39m1e-6\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mLinear dependency should be fitted with almost zero error!\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Vadim\\source\\AI-Learning\\YandexML\\task_5\\bagging.py:43\u001b[0m, in \u001b[0;36mSimplifiedBaggingRegressor.fit\u001b[1;34m(self, model_constructor, data, target)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m data\n\u001b[0;32m     41\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget \u001b[39m=\u001b[39m target\n\u001b[1;32m---> 43\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_oob_predictions_from_every_model()\n",
      "File \u001b[1;32mc:\\Users\\Vadim\\source\\AI-Learning\\YandexML\\task_5\\bagging.py:64\u001b[0m, in \u001b[0;36mSimplifiedBaggingRegressor._get_oob_predictions_from_every_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)):\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m (bag, model) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices_list, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels_list):\n\u001b[1;32m---> 64\u001b[0m         oob_indexes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49msetdiff1d(\u001b[39mrange\u001b[39;49m(\u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata)), bag)\n\u001b[0;32m     65\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39min\u001b[39;00m oob_indexes:\n\u001b[0;32m     66\u001b[0m             list_of_predictions_lists[i]\u001b[39m.\u001b[39mappend(model\u001b[39m.\u001b[39mpredict([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[i]]))\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msetdiff1d\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Vadim\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:828\u001b[0m, in \u001b[0;36msetdiff1d\u001b[1;34m(ar1, ar2, assume_unique)\u001b[0m\n\u001b[0;32m    826\u001b[0m     ar1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(ar1)\u001b[39m.\u001b[39mravel()\n\u001b[0;32m    827\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 828\u001b[0m     ar1 \u001b[39m=\u001b[39m unique(ar1)\n\u001b[0;32m    829\u001b[0m     ar2 \u001b[39m=\u001b[39m unique(ar2)\n\u001b[0;32m    830\u001b[0m \u001b[39mreturn\u001b[39;00m ar1[in1d(ar1, ar2, assume_unique\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, invert\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)]\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Vadim\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    272\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[0;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39;49mequal_nan)\n\u001b[0;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Vadim\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    334\u001b[0m     aux \u001b[39m=\u001b[39m ar[perm]\n\u001b[0;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     ar\u001b[39m.\u001b[39;49msort()\n\u001b[0;32m    337\u001b[0m     aux \u001b[39m=\u001b[39m ar\n\u001b[0;32m    338\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(aux\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool_)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(100)):\n",
    "    X = np.random.randn(2000, 10)\n",
    "    y = np.mean(X, axis=1)\n",
    "    bagging_regressor = SimplifiedBaggingRegressor(num_bags=10, oob=True)\n",
    "    bagging_regressor.fit(LinearRegression, X, y)\n",
    "    predictions = bagging_regressor.predict(X)\n",
    "    assert np.mean((predictions - y)**2) < 1e-6, 'Linear dependency should be fitted with almost zero error!'\n",
    "    assert bagging_regressor.oob, 'OOB feature must be turned on'\n",
    "    oob_score = bagging_regressor.OOB_score()\n",
    "    assert oob_score < 1e-6, 'OOB error for linear dependency should be also close to zero!'\n",
    "    assert abs(\n",
    "        np.mean(\n",
    "            list(map(len, bagging_regressor.list_of_predictions_lists))\n",
    "        ) / bagging_regressor.num_bags - 1/np.exp(1)) < 0.1, 'Probability of missing a bag should be close to theoretical value!'\n",
    "    \n",
    "print('Simple tests done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be4d037",
   "metadata": {},
   "source": [
    "#### Medium tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cfd3a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9287c643349342458853ed6d23446712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.763636363636364 19.632120558828557\n",
      "6.586363636363636 19.632120558828557\n",
      "6.681818181818182 19.632120558828557\n",
      "6.622727272727273 19.632120558828557\n",
      "6.659090909090909 19.632120558828557\n",
      "6.5 19.632120558828557\n",
      "6.5 19.632120558828557\n",
      "6.668181818181818 19.632120558828557\n",
      "6.6045454545454545 19.632120558828557\n",
      "6.7272727272727275 19.632120558828557\n",
      "Medium tests done!\n"
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(10)):\n",
    "    X = np.random.randn(200, 150)\n",
    "    y = np.random.randn(len(X))\n",
    "    bagging_regressor = SimplifiedBaggingRegressor(num_bags=20, oob=True)\n",
    "    bagging_regressor.fit(LinearRegression, X, y)\n",
    "    predictions = bagging_regressor.predict(X)\n",
    "    average_train_error = np.mean((predictions - y)**2)\n",
    "    assert bagging_regressor.oob, 'OOB feature must be turned on'\n",
    "    oob_score = bagging_regressor.OOB_score()\n",
    "    assert oob_score > average_train_error, 'OOB error must be higher than train error due to overfitting!'\n",
    "    print(np.mean(list(map(len, bagging_regressor.list_of_predictions_lists))), bagging_regressor.num_bags - 1/np.exp(1))\n",
    "    assert abs(\n",
    "        np.mean(\n",
    "            list(map(len, bagging_regressor.list_of_predictions_lists))\n",
    "        ) / bagging_regressor.num_bags - 1/np.exp(1)) < 0.1, 'Probability of missing a bag should be close to theoretical value!'\n",
    "    \n",
    "print('Medium tests done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725818ff",
   "metadata": {},
   "source": [
    "#### Complex tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f929d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e69972fb704994ad4f731194011297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.802 99.63212055882856\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Vadim\\source\\AI-Learning\\YandexML\\task_5\\assignment_bagging_and_oob.ipynb Ячейка 11\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vadim/source/AI-Learning/YandexML/task_5/assignment_bagging_and_oob.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandn(\u001b[39mlen\u001b[39m(X))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vadim/source/AI-Learning/YandexML/task_5/assignment_bagging_and_oob.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m bagging_regressor \u001b[39m=\u001b[39m SimplifiedBaggingRegressor(num_bags\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, oob\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Vadim/source/AI-Learning/YandexML/task_5/assignment_bagging_and_oob.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m bagging_regressor\u001b[39m.\u001b[39;49mfit(LinearRegression, X, y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vadim/source/AI-Learning/YandexML/task_5/assignment_bagging_and_oob.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m predictions \u001b[39m=\u001b[39m bagging_regressor\u001b[39m.\u001b[39mpredict(X)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Vadim/source/AI-Learning/YandexML/task_5/assignment_bagging_and_oob.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m oob_score \u001b[39m=\u001b[39m bagging_regressor\u001b[39m.\u001b[39mOOB_score()\n",
      "File \u001b[1;32mc:\\Users\\Vadim\\source\\AI-Learning\\YandexML\\task_5\\bagging.py:43\u001b[0m, in \u001b[0;36mSimplifiedBaggingRegressor.fit\u001b[1;34m(self, model_constructor, data, target)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m data\n\u001b[0;32m     41\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget \u001b[39m=\u001b[39m target\n\u001b[1;32m---> 43\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_oob_predictions_from_every_model()\n",
      "File \u001b[1;32mc:\\Users\\Vadim\\source\\AI-Learning\\YandexML\\task_5\\bagging.py:64\u001b[0m, in \u001b[0;36mSimplifiedBaggingRegressor._get_oob_predictions_from_every_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)):\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m (bag, model) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices_list, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels_list):\n\u001b[1;32m---> 64\u001b[0m         oob_indexes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49msetdiff1d(\u001b[39mrange\u001b[39;49m(\u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata)), bag)\n\u001b[0;32m     65\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39min\u001b[39;00m oob_indexes:\n\u001b[0;32m     66\u001b[0m             list_of_predictions_lists[i]\u001b[39m.\u001b[39mappend(model\u001b[39m.\u001b[39mpredict([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[i]]))\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msetdiff1d\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Vadim\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:829\u001b[0m, in \u001b[0;36msetdiff1d\u001b[1;34m(ar1, ar2, assume_unique)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     ar1 \u001b[39m=\u001b[39m unique(ar1)\n\u001b[1;32m--> 829\u001b[0m     ar2 \u001b[39m=\u001b[39m unique(ar2)\n\u001b[0;32m    830\u001b[0m \u001b[39mreturn\u001b[39;00m ar1[in1d(ar1, ar2, assume_unique\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, invert\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)]\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Vadim\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    272\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[0;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39;49mequal_nan)\n\u001b[0;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Vadim\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    334\u001b[0m     aux \u001b[39m=\u001b[39m ar[perm]\n\u001b[0;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     ar\u001b[39m.\u001b[39;49msort()\n\u001b[0;32m    337\u001b[0m     aux \u001b[39m=\u001b[39m ar\n\u001b[0;32m    338\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(aux\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool_)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in tqdm(range(10)):\n",
    "    X = np.random.randn(2000, 15)\n",
    "    y = np.random.randn(len(X))\n",
    "    bagging_regressor = SimplifiedBaggingRegressor(num_bags=100, oob=True)\n",
    "    bagging_regressor.fit(LinearRegression, X, y)\n",
    "    predictions = bagging_regressor.predict(X)\n",
    "    oob_score = bagging_regressor.OOB_score()\n",
    "    print(np.mean(list(map(len, bagging_regressor.list_of_predictions_lists))), bagging_regressor.num_bags - 1/np.exp(1))\n",
    "    assert abs(\n",
    "        np.mean(\n",
    "            list(map(len, bagging_regressor.list_of_predictions_lists))\n",
    "        ) / bagging_regressor.num_bags - 1/np.exp(1)) < 1e-2, 'Probability of missing a bag should be close to theoretical value!'\n",
    "    \n",
    "print('Complex tests done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af170ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.07019372688572806"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(\n",
    "            list(map(len, bagging_regressor.list_of_predictions_lists))\n",
    "        ) / bagging_regressor.num_bags - 1/np.exp(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9535cb6d",
   "metadata": {},
   "source": [
    "Great job! Please, save `SimplifiedBaggingRegressor` to  `bagging.py` and submit your solution to the grading system!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
